import os
import spacy
from spacy.language import Language
import string


nlp = spacy.load("ru_core_news_lg")


@Language.component("custom_sentence_boundary")
def set_custom_sentence_boundary(doc):
    for token in doc[:-1]:
        if token.text == '\n':
            doc[token.i + 1].is_sent_start = True
    return doc


nlp.add_pipe("custom_sentence_boundary", before="parser")


def is_pangram(sentence):
    alphabet = set("–π—Ü—É–∫–µ–Ω–≥—à—â–∑—Ö—ä—Ñ—ã–≤–∞–ø—Ä–æ–ª–¥–∂—ç—è—á—Å–º–∏—Ç—å–±—é–µÃà")
    sentence = ''.join(filter(str.isalpha, sentence.lower()))
    sentence = sentence.translate(str.maketrans("", "", string.punctuation))
    return set(sentence) == alphabet


def count_alphabet_chars(sentence):
    chars = set(filter(str.isalpha, sentence.lower()))
    return len(chars)


filename = input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è —Ñ–∞–π–ª–∞: ")

if not os.path.exists(filename):
    print(f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    exit()

print(f"–§–∞–π–ª {filename} –Ω–∞–π–¥–µ–Ω")

with open(filename, "r", encoding="utf-8") as file:
    text = file.read()

doc = nlp(text)

for sent in doc.sents:
    sentence = sent.text.strip()
    if len(sentence) < 30:
        continue
    num_chars = count_alphabet_chars(sentence)
    if num_chars >= 30:
        if is_pangram(sentence):
            print(f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: '{sentence}'")
            print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∞–ª—Ñ–∞–≤–∏—Ç–∞: {num_chars}")
            print("üéâ –≠—Ç–æ –ø–∞–Ω–≥—Ä–∞–º–º–∞! üéâ\n")
        else:
            print(f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: '{sentence}'")
            print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∞–ª—Ñ–∞–≤–∏—Ç–∞: {num_chars}")
            print("üëé –≠—Ç–æ –Ω–µ –ø–∞–Ω–≥—Ä–∞–º–º–∞. üëé\n")
